# tech-challenge-3




- utilizamos o gemma-3-4b-it-Q8_0.gguf

## Datasets

### Corre√ß√£o e Limpeza de Dados.

#### pre limpeza
- normaliza_dado.py

#### apaga linhas desnecessarias.
- apaga_linhas.py

# Tech Challenge FASE 03: Fine-Tuning do Gemma para Perguntas e Respostas de Produtos

## üéØ Objetivo do Projeto

Este projeto realiza o fine-tuning de um modelo de linguagem (LLM) para atuar como um especialista em produtos. O modelo foi treinado para receber o t√≠tulo de um produto da Amazon e retornar sua descri√ß√£o detalhada, baseado no dataset "The Amazon Titles-1.3MM".

## üõ†Ô∏è Tecnologias e Modelos Utilizados

- **Modelo Base:** Google Gemma (vers√£o quantizada GGUF `gemma-3-4b-it-Q8_0.gguf`)
- **Dataset:** The Amazon Titles-1.3MM (`trn.json`)
- **Bibliotecas Principais:** Pandas, Hugging Face Transformers, ctransformers, PyTorch
- **Ambiente de Treinamento:** Google Cloud

## üìö LLM models

- [hunggingface](https://huggingface.co/)
- [gemma-3-4b-it](https://huggingface.co/google/gemma-3-4b-it)
- [modulo gguf quantizado](https://huggingface.co/ggml-org/gemma-3-4b-it-GGUF)

## üìÇ Estrutura do Reposit√≥rio

- `data/`: Cont√©m o dataset original e os dados tratados.
- `scripts/`:
    - `normaliza_dado.py`: Script para limpeza e normaliza√ß√£o inicial dos dados.
    - `apaga_linhas.py`: Script para filtrar e remover dados desnecess√°rios.
- `notebooks/`:
    - `Fine_Tuning_Gemma.ipynb`: Notebook principal com todo o processo de fine-tuning.
- `README.md`: Este documento.

## üöÄ Como Executar

1.  Clone o reposit√≥rio: `git clone ...`
2.  Instale as depend√™ncias: `pip install -r requirements.txt`
3.  Execute o notebook `notebooks/Fine_Tuning_Gemma.ipynb` para ver o processo completo.