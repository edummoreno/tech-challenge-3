# Tech Challenge FASE 03: Fine-Tuning do Gemma para Perguntas e Respostas de Produtos

## ğŸ¯ Objetivo do Projeto

Este projeto realiza o fine-tuning de um modelo de linguagem (LLM) para atuar como um especialista em produtos. O modelo foi treinado para receber o tÃ­tulo de um produto da Amazon e retornar sua descriÃ§Ã£o detalhada, baseado no dataset "The Amazon Titles-1.3MM".

## ğŸ› ï¸ Tecnologias e Modelos Utilizados

- **Modelo Base:** Google Gemma (versÃ£o quantizada GGUF `gemma-3-4b-it-Q8_0.gguf`)
- **Dataset:** The Amazon Titles-1.3MM (`trn.json`)
- **Bibliotecas Principais:** Pandas, Hugging Face Transformers, ctransformers, PyTorch
- **Ambiente de Treinamento:** Google Cloud

## ğŸ“š LLM models

- [hunggingface](https://huggingface.co/)
- [gemma-3-4b-it](https://huggingface.co/google/gemma-3-4b-it)
- [modulo gguf quantizado](https://huggingface.co/ggml-org/gemma-3-4b-it-GGUF)

## ğŸ“‚ Estrutura do RepositÃ³rio

- `data/`: ContÃ©m o dataset original e os dados tratados.
- `scripts/`:
    - `normaliza_dado.py`: Script para limpeza e normalizaÃ§Ã£o inicial dos dados.
    - `apaga_linhas.py`: Script para filtrar e remover dados desnecessÃ¡rios.
- `notebooks/`:
    - `Fine_Tuning_Gemma.ipynb`: Notebook principal com todo o processo de fine-tuning.
- `README.md`: Este documento.

## ğŸš€ Como Executar

1.  Clone o repositÃ³rio: `git clone ...`
2.  Instale as dependÃªncias: `pip install -r requirements.txt`
3.  Execute o notebook `notebooks/Fine_Tuning_Gemma.ipynb` para ver o processo completo.